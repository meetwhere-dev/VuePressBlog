<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Hello OpenCV.js</title>
<style>
  .img_dectect, .video_dectect{
    display: flex;
  }
  .caption {
    text-align: center;
    border: 2px solid rgb(6, 155, 193);
    border-radius: 10px;
  }
</style>
</head>
<body>
<h2>Hello OpenCV.js</h2>
<p id="status">OpenCV.js 读取中...</p>
<div>
  <h1>图片人脸识别</h1>
  <div><input type="file" id="imgInput" name="file" accept="image/*"> 请上传需要识别的图片</div>
  <button id="imgDectectButton" disabled>正在读取OpenCV...</button>
  <div class="img_dectect">
    <div class="caption"><p>图片输入</p> <canvas id="imgCanvasInput" width="640"  height="480"></canvas></div>
    <div class="caption"><p>输出识别</p> <canvas id="imgCanvasOutput" width="640"  height="480"></canvas></div>
  </div>

  <h1>视频人脸识别</h1>
  <button id="videoDectectButton" disabled>正在读取OpenCV...</button>
  <div class="video_dectect">
    <div class="caption">视频输入<video id="videoInput"  width="640"  height="480"></video></div>
    <div class="caption">视频输出<canvas id="canvasOutput" width="640"  height="480" ></canvas></div>
    <div class="caption">视频中间状态输出<canvas id="canvasOutput2"></canvas></div>
  </div>


</div>
<script type="text/javascript">
let imgDectectButton = document.getElementById('imgDectectButton');
imgDectectButton.addEventListener('click', startImgDectect);
let inputElement = document.getElementById('imgInput');
let imgCanvasInput = document.getElementById('imgCanvasInput');
let imgCanvasOutput = document.getElementById('imgCanvasOutput');
inputElement.addEventListener('change', (e) => {
    let files = e.target.files;
    if (files.length > 0) {
        let imgUrl = URL.createObjectURL(files[0]);
        let ctx = imgCanvasInput.getContext('2d');
        let img = new Image();
        img.crossOrigin = 'anonymous';
        img.onload = function() {
            imgCanvasInput.width = img.width;
            imgCanvasInput.height = img.height;
            imgCanvasOutput.width = img.width;
            imgCanvasOutput.height = img.height;
            ctx.drawImage(img, 0, 0, img.width, img.height);
        };
        img.src = imgUrl;
    }
}, false);

function startImgDectect () {
  let src = new cv.imread('imgCanvasInput');  // 读取canvas内图片 放入容器
  let gray = new cv.Mat();
  cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
  let classifier = new cv.CascadeClassifier(); // 级联 分类器
  classifier.load('face.xml'); // 加载训练模型
  let faces = new cv.RectVector();
  classifier.detectMultiScale(gray, faces, 1.1, 3, 0); // 侦测脸部
  for (let i = 0; i < faces.size(); ++i) {
      let roiGray = gray.roi(faces.get(i));
      let roiSrc = src.roi(faces.get(i));
      let point1 = new cv.Point(faces.get(i).x, faces.get(i).y);
      let point2 = new cv.Point(faces.get(i).x + faces.get(i).width,
                                faces.get(i).y + faces.get(i).height);
      cv.rectangle(src, point1, point2, [255, 0, 0, 255]);
  }
  
  // 绘制到canvas
  cv.imshow('imgCanvasOutput', src);

  // 清除缓存
  src.delete();
  gray.delete();
  classifier.delete();
}


//  ----------------------- 视频人脸识别系统 ----------------------
let videoDectectButton = document.getElementById('videoDectectButton');
videoDectectButton.addEventListener('click', startVideo);
let video = document.getElementById('videoInput');

function startVideo() {
  let src = new cv.Mat(video.height, video.width, cv.CV_8UC4); // 图像容器 8位 4通道
  let gray = new cv.Mat();  // 灰度图容器
  let cap = new cv.VideoCapture(video); // 视频采集器
  let classifier = new cv.CascadeClassifier(); // 级联 分类器
  classifier.load('face.xml'); // 加载训练模型

  const FPS = 30;
  function processVideo() {
    let begin = Date.now();
    // 截取一帧图像
    cap.read(src);

    // 转换为灰度图
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

    
    let downSampled = new cv.Mat();
    cv.pyrDown(gray, downSampled); // 把图片变小点 以减少侦测时间
    cv.pyrDown(downSampled, downSampled);

    // 侦测脸部
    let faces = new cv.RectVector();
    classifier.detectMultiScale(downSampled, faces); // 侦测脸部

    // 绘制边框
    let size = downSampled.size();
    let xRatio = video.width / size.width;
    let yRatio = video.height / size.height;
    for (let i = 0; i < faces.size(); ++i) {
        let face = faces.get(i);
        let point1 = new cv.Point(face.x * xRatio, face.y * yRatio);
        let point2 = new cv.Point((face.x + face.width) * xRatio, (face.y + face.height) * xRatio);
        cv.rectangle(src, point1, point2, [255, 0, 0, 255])
    }

    // 绘制最终结果
    cv.imshow('canvasOutput', src);
    cv.imshow('canvasOutput2', downSampled);

    // 释放内存
    downSampled.delete();
    faces.delete();

    let delay = 1000/FPS - (Date.now() - begin);
    setTimeout(processVideo, delay);
  };
  setTimeout(processVideo, 0);
}

// 读取摄像头api 输出到canvas
let constraints = { audio: false, video: { width: video.width, height: video.height } }; 
navigator.mediaDevices.getUserMedia(constraints)
.then(function(mediaStream) {
  let video = document.getElementById('videoInput');
  video.srcObject = mediaStream;
  video.onloadedmetadata = function(e) {
    video.play();
  };
})
.catch(function(err) { console.log(err.name + ": " + err.message); });


// 读取训练模型 人脸识别 需要用
function loadXmlData() {
  let request = new XMLHttpRequest();
  request.open('GET', 'face.xml');
  request.responseType = 'arraybuffer';
  request.onload = function(ev) {
      if (request.readyState === 4) {
          if (request.status === 200) {
              let data = new Uint8Array(request.response);
              cv.FS_createDataFile('/', 'face.xml', data, true, false, false);
              imgDectectButton.removeAttribute('disabled');
              videoDectectButton.removeAttribute('disabled');
              document.getElementById('status').innerHTML = 'OpenCV.js 已就绪.';
              imgDectectButton.innerHTML = '开始识别';
              videoDectectButton.innerHTML = '开始识别';
          }
      }
  };
  request.send();
}

// 等待opencv读取系统信息
async function onOpenCvReady() {
  if (cv.getBuildInformation) {
      console.log(cv.getBuildInformation());
      loadXmlData();
  } else {
    if (cv instanceof Promise) {
      cv = await cv;
      console.log(cv.getBuildInformation());
      loadXmlData();
    } else {
      cv.onRuntimeInitialized = () => {
        console.log(cv.getBuildInformation());
        loadXmlData();
      }
    }
  }
}
</script>
<script async src="opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
</body>
</html>