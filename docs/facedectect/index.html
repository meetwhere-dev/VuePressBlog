<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Hello OpenCV.js</title>
<style>
  #inputoutput{
    display: flex;
  }
</style>
</head>
<body>
<h2>Hello OpenCV.js</h2>
<p id="status">OpenCV.js is loading...</p>
<div>
  <button id="begin">kaishi</button>
  <div class="inputoutput">
    <video id="videoInput"  width="640"  height="480"></video>
    <canvas id="canvasOutput" width="640"  height="480" ></canvas>
    <div class="caption">canvasOutput</div>
  </div>
</div>
<script type="text/javascript">
let beginButton = document.getElementById('begin');
beginButton.addEventListener('click', startVideo);

function startVideo() {


  let video = document.getElementById('videoInput');
  let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
  let dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
  let gray = new cv.Mat();
  let cap = new cv.VideoCapture(video);
  let classifier = new cv.CascadeClassifier();
  classifier.load('face.xml');

  const FPS = 30;
  function processVideo() {
    let begin = Date.now();
    // Capture a frame
    cap.read(src)

    // Convert to greyscale
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

    // Downsample
    let downSampled = new cv.Mat();
    cv.pyrDown(gray, downSampled);
    cv.pyrDown(downSampled, downSampled);

    // Detect faces
    let faces = new cv.RectVector();
    classifier.detectMultiScale(downSampled, faces)

    // Draw boxes
    let size = downSampled.size();
    let xRatio = 640 / size.width;
    let yRatio = 480 / size.height;
    for (let i = 0; i < faces.size(); ++i) {
        let face = faces.get(i);
        let point1 = new cv.Point(face.x * xRatio, face.y * yRatio);
        let point2 = new cv.Point((face.x + face.width) * xRatio, (face.y + face.height) * xRatio);
        cv.rectangle(src, point1, point2, [255, 0, 0, 255])
    }

    // Show image
    cv.imshow('canvasOutput', src)

    // Cleanup
    downSampled.delete()
    faces.delete()

// 11111
    // let gray = new cv.Mat();
    // let faces = new cv.RectVector();
    // // start processing.
    // cap.read(src);
    // src.copyTo(dst);
    // cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
    // // detect faces.
    // classifier.detectMultiScale(gray, faces);


    // // draw faces.
    // for (let i = 0; i < faces.size(); ++i) {
    //   let face = faces.get(i);
    //   let point1 = new cv.Point(face.x, face.y);
    //   let point2 = new cv.Point(face.x + face.width, face.y + face.height);
    //   cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
    // }
    // cv.imshow('canvasOutput', dst);

    // gray.delete()
    // faces.delete()
    // schedule the next one.
    let delay = 1000/FPS - (Date.now() - begin);
    setTimeout(processVideo, delay);
  };

  // schedule the first one.
  setTimeout(processVideo, 0);
}


// 想要获取一个最接近 1280x720 的相机分辨率
var constraints = { audio: true, video: { width: 640, height: 480 } }; 


if (navigator.mediaDevices === undefined) {
  navigator.mediaDevices = {};
}
if (navigator.mediaDevices.getUserMedia === undefined) {
  navigator.mediaDevices.getUserMedia = function (constraints) {
    var getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia || navigator.oGetUserMedia;
    if (!getUserMedia) {
      return Promise.reject(new Error('getUserMedia is not implemented in this browser'));
    }
    return new Promise(function (resolve, reject) {
      getUserMedia.call(navigator, constraints, resolve, reject);
    });
  }
}


navigator.mediaDevices.getUserMedia(constraints)
.then(function(mediaStream) {
  let video = document.getElementById('videoInput');
  video.srcObject = mediaStream;
  video.onloadedmetadata = function(e) {
    video.play();
  };
})
.catch(function(err) { console.log(err.name + ": " + err.message); }); // 总是在最后检查错误



function loadXmlData() {
  let classifier = new cv.CascadeClassifier();
  let request = new XMLHttpRequest();
  request.open('GET', 'face.xml');
  request.responseType = 'arraybuffer';
  request.onload = function(ev) {
      if (request.readyState === 4) {
          if (request.status === 200) {
              let data = new Uint8Array(request.response);
              cv.FS_createDataFile('/', 'face.xml', data, true, false, false);
          }
      }
  };
  request.send();
}

async function onOpenCvReady() {
  if (cv.getBuildInformation) {
      console.log(cv.getBuildInformation());
      loadXmlData();
  } else {
    if (cv instanceof Promise) {
      cv = await cv;
      console.log(cv.getBuildInformation());
      loadXmlData();
    } else {
      cv.onRuntimeInitialized = () => {
        console.log(cv.getBuildInformation());
        loadXmlData();
      }
    }
  }

  document.getElementById('status').innerHTML = 'OpenCV.js is ready.';
}
</script>
<script async src="opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
</body>
</html>